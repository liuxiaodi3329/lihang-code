{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4章 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．朴素贝叶斯法是典型的生成学习方法。生成方法由训练数据学习联合概率分布\n",
    "$P(X,Y)$，然后求得后验概率分布$P(Y|X)$。具体来说，利用训练数据学习$P(X|Y)$和$P(Y)$的估计，得到联合概率分布：\n",
    "\n",
    "$$P(X,Y)＝P(Y)P(X|Y)$$\n",
    "\n",
    "概率估计方法可以是极大似然估计或贝叶斯估计。\n",
    "\n",
    "2．朴素贝叶斯法的基本假设是条件独立性，\n",
    "\n",
    "$$\\begin{aligned} P(X&=x | Y=c_{k} )=P\\left(X^{(1)}=x^{(1)}, \\cdots, X^{(n)}=x^{(n)} | Y=c_{k}\\right) \\\\ &=\\prod_{j=1}^{n} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right) \\end{aligned}$$\n",
    "\n",
    "\n",
    "这是一个较强的假设。由于这一假设，模型包含的条件概率的数量大为减少，朴素贝叶斯法的学习与预测大为简化。因而朴素贝叶斯法高效，且易于实现。其缺点是分类的性能不一定很高。\n",
    "\n",
    "3．朴素贝叶斯法利用贝叶斯定理与学到的联合概率模型进行分类预测。\n",
    "\n",
    "$$P(Y | X)=\\frac{P(X, Y)}{P(X)}=\\frac{P(Y) P(X | Y)}{\\sum_{Y} P(Y) P(X | Y)}$$\n",
    " \n",
    "将输入$x$分到后验概率最大的类$y$。\n",
    "\n",
    "$$y=\\arg \\max _{c_{k}} P\\left(Y=c_{k}\\right) \\prod_{j=1}^{n} P\\left(X_{j}=x^{(j)} | Y=c_{k}\\right)$$\n",
    "\n",
    "后验概率最大等价于0-1损失函数时的期望风险最小化。\n",
    "\n",
    "\n",
    "模型：\n",
    "\n",
    "- 高斯模型\n",
    "- 多项式模型\n",
    "- 伯努利模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np#导入 NumPy 库，并将其命名为 np，这样我们就可以用 np 代替 numpy 进行调用。\n",
    "import pandas as pd#导入 Pandas 库，并将其命名为 pd，这样我们就可以用 pd 代替 pandas 进行调用。\n",
    "import matplotlib.pyplot as plt#导入 Matplotlib 库中的 pyplot 模块，并将其命名为 plt，这样我们就可以用 plt 代替 pyplot 进行调用\n",
    "%matplotlib inline#在 notebook 中显示 Matplotlib 等绘图库的图形\n",
    "\n",
    "from sklearn.datasets import load_iris#从 Scikit-Learn 库中导入 iris 数据集，它包含了三个类别的鸢尾花的各种特征，可用于分类问题的建模\n",
    "from sklearn.model_selection import train_test_split#从 Scikit-Learn 库中导入 train_test_split 函数，用于将数据集划分为训练集和测试集，以进行交叉验证\n",
    "\n",
    "from collections import Counter#导入 collections 库中的 Counter 类，它用于计算一个序列的元素频次\n",
    "import math#导入 Python 内置的 math 模块，该模块提供了一些常用的数学函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def create_data():\n",
    "    iris = load_iris()#调用了 load_iris() 函数，该函数可用于加载 sklearn 中自带的鸢尾花数据集\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)#将 iris 数据集中的特征值（即花萼长度、花萼宽度、花瓣长度、花瓣宽度）和列名（feature_names）转换为了 DataFrame 格式，并存储在 df 变量中\n",
    "    df['label'] = iris.target#将 iris 数据集中的目标值（即品种）存储在 label 列中\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']#将数据集中的列名进行修改\n",
    "    data = np.array(df.iloc[:100, :])#将前 100 行的数据存储在 data 变量中。\n",
    "    # print(data)\n",
    "    return data[:,:-1], data[:,-1]#将数据分为两部分：特征值 data[:,:-1] 和目标值（标签）data[:,-1]，并返回给模型使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()#调用 create_data() 函数，并将返回的特征矩阵 X 和标签 y 分别赋值给变量 X 和 y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)# 使用 train_test_split() 函数将 X 和 y 随机划分为训练集（X_train, y_train）和测试集（X_test, y_test），其中 test_size=0.3 表示将数据集按 7:3 的比例划分为训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.1, 3.8, 1.9, 0.4]), 0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
    "\n",
    "## GaussianNB 高斯朴素贝叶斯\n",
    "\n",
    "特征的可能性被假设为高斯\n",
    "\n",
    "概率密度函数：\n",
    "$$P(x_i | y_k)=\\frac{1}{\\sqrt{2\\pi\\sigma^2_{yk}}}exp(-\\frac{(x_i-\\mu_{yk})^2}{2\\sigma^2_{yk}})$$\n",
    "\n",
    "数学期望(mean)：$\\mu$\n",
    "\n",
    "方差：$\\sigma^2=\\frac{\\sum(X-\\mu)^2}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):#初始化一个空的模型\n",
    "        self.model = None\n",
    "\n",
    "    # 数学期望\n",
    "    @staticmethod\n",
    "    def mean(X):#计算数组 X 的数学期望\n",
    "        return sum(X) / float(len(X))\n",
    "\"\"\"\n",
    "求平均数的方式，其中X是作为参数传递给函数的一个列表，\n",
    "sum 函数将X中所有元素的和计算出来，\n",
    "len 函数计算列表 X 的长度，两者相除即可得到平均值。\n",
    "这里使用 float 将结果强制转换为浮点数以避免整数除法产生的问题。\n",
    "\"\"\"\n",
    "    # 标准差（方差）\n",
    "    def stdev(self, X):#计算数组 X 的标准差（方差）\n",
    "        avg = self.mean(X)#计算数组 X 的平均值并将其赋值给变量 avg\n",
    "        return math.sqrt(sum([pow(x - avg, 2) for x in X]) / float(len(X)))#推导式计算方差，调用 Python 自带 math 库中的 sqrt() 函数求出标准差，将其返回\n",
    "\n",
    "    # 概率密度函数\n",
    "    def gaussian_probability(self, x, mean, stdev):#计算高斯概率密度函数\n",
    "         #定义一个指数部分的计算结果 exponent，使用了 math.pow() 函数来计算平方；然后使用 math.exp() 函数计算指数部分的值。\n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) /\n",
    "                              (2 * math.pow(stdev, 2))))\n",
    "       #使用 math.sqrt() 函数和常数 math.pi 处理公式的前部分。最后，返回概率密度函数的值\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "    # 处理X_train\n",
    "    def summarize(self, train_data):#计算训练数据集每个特征的数学期望和标准差，并返回一个列表\n",
    "        summaries = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)]\n",
    "        return summaries\n",
    "\n",
    "    # 分类别求出数学期望和标准差\n",
    "    def fit(self, X, y):#使用训练数据 X 和标签 y 训练模型，并返回训练完成的消息\n",
    "        labels = list(set(y))\n",
    "        data = {label: [] for label in labels}\n",
    "        for f, label in zip(X, y):\n",
    "            data[label].append(f)\n",
    "        self.model = {\n",
    "            label: self.summarize(value)\n",
    "            for label, value in data.items()\n",
    "        }\n",
    "        return 'gaussianNB train done!'\n",
    "\n",
    "    # 计算概率\n",
    "    def calculate_probabilities(self, input_data):#利用训练好的模型，计算输入数据的分类概率\n",
    "        # summaries:{0.0: [(5.0, 0.37),(3.42, 0.40)], 1.0: [(5.8, 0.449),(2.7, 0.27)]}\n",
    "        # input_data:[1.1, 2.2]\n",
    "        probabilities = {}# 定义一个空字典来存储各个类别出现的概率\n",
    "\n",
    "        for label, value in self.model.items():# 遍历所有类别，计算出现概率。label 是类别名称，value 是对应类别的高斯分布模型\n",
    "            probabilities[label] = 1#初始化概率为 1\n",
    "            for i in range(len(value)):#逐一计算每个输入特征在该类别下的概率\n",
    "                mean, stdev = value[i] # 取出该特征的均值和标准差\n",
    "                probabilities[label] *= self.gaussian_probability(#计算该特征在该类别下对应的高斯分布概率，并将所有特征概率相乘\n",
    "                    input_data[i], mean, stdev)\n",
    "        return probabilities# 返回所有类别的概率\n",
    "\n",
    "    # 类别\n",
    "    def predict(self, X_test):#基于输入测试数据 X_test，预测分类标签\n",
    "        # {0.0: 2.9680340789325763e-27, 1.0: 3.5749783019849535e-26}\n",
    "        label = sorted(#定义一个变量 label，用来保存预测的标签。使用 sorted 函数对 calculate_probabilities 的返回结果进行排序。\n",
    "            self.calculate_probabilities(X_test).items(),#调用 calculate_probabilities 函数，并使用 items() 方法获取其返回的字典中所有的键值对，即每个可能标签对应的概率值。\n",
    "            key=lambda x: x[-1])[-1][0]#使用 lambda 表达式对上一步返回的键值对列表进行排序，按照每个键值对中的最后一个元素（即概率值）升序排序，这里的 -1 表示最后一个元素。\n",
    "        return label\n",
    "\n",
    "    def score(self, X_test, y_test):#计算分类器在测试数据集上的准确率，并返回准确率\n",
    "        right = 0# 初始化分类正确的数量为 0\n",
    "        for X, y in zip(X_test, y_test):# 对测试集中的每个样本，进行预测并进行结果统计\n",
    "            label = self.predict(X)# 对当前样本进行预测\n",
    "            if label == y: # 比较预测值和真实标签是否相同\n",
    "                right += 1# 如果相同，则分类正确数量加 1\n",
    "\n",
    "        return right / float(len(X_test))# 返回测试集上的分类精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes()#实例化了一个名为 model 的朴素贝叶斯分类器对象。这个对象可以用来进行分类任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gaussianNB train done!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)#通过训练数据 X_train 和对应的标签 y_train 来训练机器学习模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([4.4,  3.2,  1.3,  0.2]))#使用机器学习模型对一个样本进行预测\n",
    "\"\"\"\n",
    "model.predict() 函数可以用来预测新数据点的标签（label）或分类。\n",
    "在这里，输入的样本特征为 [4.4,  3.2,  1.3,  0.2]，也就是一组花的测量值，\n",
    "输出的结果应该是这朵花的类别\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)## 评估分类器的精度，使用测试数据 X_test 和 y_test,X_test是测试数据集的特征变量，y_test是测试数据集的目标变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### scikit-learn实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB# 从 sklearn 库中引入 GaussianNB 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()# 创建一个 GaussianNB 类的实例 clf\n",
    "clf.fit(X_train, y_train)# 使用训练数据 X_train 和 y_train 对分类器进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)# 评估分类器的精度，使用测试数据 X_test 和 y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4.4,  3.2,  1.3,  0.2]])# 对新数据进行预测，使用clf.predict()函数，新数据是一个包含 4 个特征值的一维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB # 伯努利模型和多项式模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "参考代码：https://github.com/wzyonggege/statistical-learning-method\n",
    "\n",
    "本文代码更新地址：https://github.com/fengdu78/lihang-code\n",
    "\n",
    "中文注释制作：机器学习初学者公众号：ID:ai-start-com\n",
    "\n",
    "配置环境：python 3.5+\n",
    "\n",
    "代码全部测试通过。\n",
    "![gongzhong](../gongzhong.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
