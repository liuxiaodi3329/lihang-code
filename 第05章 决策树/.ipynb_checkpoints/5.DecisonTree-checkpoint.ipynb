{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．分类决策树模型是表示基于特征对实例进行分类的树形结构。决策树可以转换成一个**if-then**规则的集合，也可以看作是定义在特征空间划分上的类的条件概率分布。\n",
    "\n",
    "2．决策树学习旨在构建一个与训练数据拟合很好，并且复杂度小的决策树。因为从可能的决策树中直接选取最优决策树是NP完全问题。现实中采用启发式方法学习次优的决策树。\n",
    "\n",
    "决策树学习算法包括3部分：特征选择、树的生成和树的剪枝。常用的算法有ID3、\n",
    "C4.5和CART。\n",
    "\n",
    "3．特征选择的目的在于选取对训练数据能够分类的特征。特征选择的关键是其准则。常用的准则如下：\n",
    "\n",
    "（1）样本集合$D$对特征$A$的信息增益（ID3）\n",
    "\n",
    "\n",
    "$$g(D, A)=H(D)-H(D|A)$$\n",
    "\n",
    "$$H(D)=-\\sum_{k=1}^{K} \\frac{\\left|C_{k}\\right|}{|D|} \\log _{2} \\frac{\\left|C_{k}\\right|}{|D|}$$\n",
    "\n",
    "$$H(D | A)=\\sum_{i=1}^{n} \\frac{\\left|D_{i}\\right|}{|D|} H\\left(D_{i}\\right)$$\n",
    "\n",
    "其中，$H(D)$是数据集$D$的熵，$H(D_i)$是数据集$D_i$的熵，$H(D|A)$是数据集$D$对特征$A$的条件熵。\t$D_i$是$D$中特征$A$取第$i$个值的样本子集，$C_k$是$D$中属于第$k$类的样本子集。$n$是特征$A$取 值的个数，$K$是类的个数。\n",
    "\n",
    "（2）样本集合$D$对特征$A$的信息增益比（C4.5）\n",
    "\n",
    "\n",
    "$$g_{R}(D, A)=\\frac{g(D, A)}{H(D)}$$\n",
    "\n",
    "\n",
    "其中，$g(D,A)$是信息增益，$H(D)$是数据集$D$的熵。\n",
    "\n",
    "（3）样本集合$D$的基尼指数（CART）\n",
    "\n",
    "$$\\operatorname{Gini}(D)=1-\\sum_{k=1}^{K}\\left(\\frac{\\left|C_{k}\\right|}{|D|}\\right)^{2}$$\n",
    "\n",
    "特征$A$条件下集合$D$的基尼指数：\n",
    "\n",
    " $$\\operatorname{Gini}(D, A)=\\frac{\\left|D_{1}\\right|}{|D|} \\operatorname{Gini}\\left(D_{1}\\right)+\\frac{\\left|D_{2}\\right|}{|D|} \\operatorname{Gini}\\left(D_{2}\\right)$$\n",
    " \n",
    "4．决策树的生成。通常使用信息增益最大、信息增益比最大或基尼指数最小作为特征选择的准则。决策树的生成往往通过计算信息增益或其他指标，从根结点开始，递归地产生决策树。这相当于用信息增益或其他准则不断地选取局部最优的特征，或将训练集分割为能够基本正确分类的子集。\n",
    "\n",
    "5．决策树的剪枝。由于生成的决策树存在过拟合问题，需要对它进行剪枝，以简化学到的决策树。决策树的剪枝，往往从已生成的树上剪掉一些叶结点或叶结点以上的子树，并将其父结点或根结点作为新的叶结点，从而简化生成的决策树。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必要的库\n",
    "import numpy as np # 数据处理库\n",
    "import pandas as pd # 数据处理库\n",
    "import matplotlib.pyplot as plt# 可视化库\n",
    "%matplotlib inline# 在jupyter notebook中可直接显示图形\n",
    "#导入数据集和划分函数\n",
    "from sklearn.datasets import load_iris # 加载iris数据集\n",
    "from sklearn.model_selection import train_test_split# 分割数据集为训练集和测试集\n",
    "#导入计数器和数学库\n",
    "from collections import Counter# 用于计数\n",
    "import math # 数学库\n",
    "from math import log # 求对数\n",
    "import pprint# 漂亮打印函数，用于打印字典、列表等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 书上题目5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 书上题目5.1\n",
    "def create_data():\n",
    "    datasets = [['青年', '否', '否', '一般', '否'], # 数据样本1\n",
    "               ['青年', '否', '否', '好', '否'], # 数据样本2\n",
    "               ['青年', '是', '否', '好', '是'], # 数据样本3\n",
    "               ['青年', '是', '是', '一般', '是'], # 数据样本4\n",
    "               ['青年', '否', '否', '一般', '否'], # 数据样本5\n",
    "               ['中年', '否', '否', '一般', '否'], # 数据样本6\n",
    "               ['中年', '否', '否', '好', '否'], # 数据样本7\n",
    "               ['中年', '是', '是', '好', '是'], # 数据样本8\n",
    "               ['中年', '否', '是', '非常好', '是'], # 数据样本9\n",
    "               ['中年', '否', '是', '非常好', '是'], # 数据样本10\n",
    "               ['老年', '否', '是', '非常好', '是'], # 数据样本11\n",
    "               ['老年', '否', '是', '好', '是'], # 数据样本12\n",
    "               ['老年', '是', '否', '好', '是'], # 数据样本13\n",
    "               ['老年', '是', '否', '非常好', '是'], # 数据样本14\n",
    "               ['老年', '否', '否', '一般', '否'], # 数据样本15\n",
    "               ]\n",
    "    labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']# 数据集每个维度的名称\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return datasets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, labels = create_data()#使用 create_data() 函数生成训练集数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(datasets, columns=labels)#将数据转换为 pandas DataFrame 格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>年龄</th>\n",
       "      <th>有工作</th>\n",
       "      <th>有自己的房子</th>\n",
       "      <th>信贷情况</th>\n",
       "      <th>类别</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>青年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>青年</td>\n",
       "      <td>是</td>\n",
       "      <td>是</td>\n",
       "      <td>一般</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中年</td>\n",
       "      <td>是</td>\n",
       "      <td>是</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>老年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>老年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    年龄 有工作 有自己的房子 信贷情况 类别\n",
       "0   青年   否      否   一般  否\n",
       "1   青年   否      否    好  否\n",
       "2   青年   是      否    好  是\n",
       "3   青年   是      是   一般  是\n",
       "4   青年   否      否   一般  否\n",
       "5   中年   否      否   一般  否\n",
       "6   中年   否      否    好  否\n",
       "7   中年   是      是    好  是\n",
       "8   中年   否      是  非常好  是\n",
       "9   中年   否      是  非常好  是\n",
       "10  老年   否      是  非常好  是\n",
       "11  老年   否      是    好  是\n",
       "12  老年   是      否    好  是\n",
       "13  老年   是      否  非常好  是\n",
       "14  老年   否      否   一般  否"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data#打印数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 熵\n",
    "def calc_ent(datasets):\n",
    "    data_length = len(datasets)# 数据集样本总数\n",
    "    label_count = {}\n",
    "    for i in range(data_length):\n",
    "        label = datasets[i][-1] # 获取当前样本的标签\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 0 # 如果该标签第一次出现，将其加入统计字典中\n",
    "        label_count[label] += 1 # 统计该标签出现的次数\n",
    "    ent = -sum([(p / data_length) * log(p / data_length, 2)# 计算信息熵\n",
    "                for p in label_count.values()])\n",
    "    return ent#返回信息熵的值\n",
    "# def entropy(y):\n",
    "#     \"\"\"\n",
    "#     Entropy of a label sequence\n",
    "#     \"\"\"\n",
    "#     hist = np.bincount(y)\n",
    "#     ps = hist / np.sum(hist)\n",
    "#     return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "\n",
    "# 经验条件熵\n",
    "def cond_ent(datasets, axis=0):\n",
    "    data_length = len(datasets) # 数据集样本总数\n",
    "    feature_sets = {}# 初始化空字典，用于将数据按照某一特征分组\n",
    "    for i in range(data_length):\n",
    "        feature = datasets[i][axis]# 获取第axis个特征值\n",
    "        if feature not in feature_sets:\n",
    "            feature_sets[feature] = []\n",
    "        feature_sets[feature].append(datasets[i])  # 将具有相同特征值的数据添加到同一组\n",
    "    cond_ent = sum(\n",
    "        [(len(p) / data_length) * calc_ent(p) for p in feature_sets.values()])#对于每个特征值组，按照该组中样本占比计算熵，并求和\n",
    "    return cond_ent#返回条件熵的值\n",
    "\n",
    "\n",
    "# 信息增益\n",
    "def info_gain(ent, cond_ent):\n",
    "    return ent - cond_ent\n",
    "\n",
    "\n",
    "def info_gain_train(datasets):\n",
    "    count = len(datasets[0]) - 1# 特征数\n",
    "    ent = calc_ent(datasets)# 计算数据集的信息熵\n",
    "#     ent = entropy(datasets)# 保存每个特征的信息增益\n",
    "    best_feature = []\n",
    "    for c in range(count):\n",
    "        c_info_gain = info_gain(ent, cond_ent(datasets, axis=c)) # 计算每个特征的信息增益\n",
    "        best_feature.append((c, c_info_gain))# 将特征及其信息增益添加到最佳特征列表中\n",
    "        print('特征({}) - info_gain - {:.3f}'.format(labels[c], c_info_gain))\n",
    "    # 比较大小\n",
    "    best_ = max(best_feature, key=lambda x: x[-1])# 找到最大的信息增益并返回对应的特征\n",
    "    return '特征({})的信息增益最大，选择为根节点特征'.format(labels[best_[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征(年龄) - info_gain - 0.083\n",
      "特征(有工作) - info_gain - 0.324\n",
      "特征(有自己的房子) - info_gain - 0.420\n",
      "特征(信贷情况) - info_gain - 0.363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'特征(有自己的房子)的信息增益最大，选择为根节点特征'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_gain_train(np.array(datasets))# 将数据集转换为numpy数组，并传入 info_gain_train 函数中进行特征选择和建立决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "利用ID3算法生成决策树，例5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义节点类 二叉树\n",
    "class Node:\n",
    "    def __init__(self, root=True, label=None, feature_name=None, feature=None):\n",
    "        \"\"\"\n",
    "        :param root: bool, True表示当前节点为根节点，False表示非根节点\n",
    "        :param label: string, 叶节点表示的类别\n",
    "        :param feature_name: string, 当前节点表示的特征名称\n",
    "        :param feature: int, 当前节点表示的特征编号\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.label = label\n",
    "        self.feature_name = feature_name\n",
    "        self.feature = feature\n",
    "        self.tree = {} # 子树，使用字典表示\n",
    "        self.result = { # 该节点表示的结果信息（用于输出决策树的结果）\n",
    "            'label:': self.label,\n",
    "            'feature': self.feature,\n",
    "            'tree': self.tree\n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        重载Node类的输出方法，方便显示决策树的结果\n",
    "        \"\"\"\n",
    "        return '{}'.format(self.result)\n",
    "\n",
    "    def add_node(self, val, node):\n",
    "        \"\"\"\n",
    "        为当前节点添加一个子节点\n",
    "        :param val: 特征取值\n",
    "        :param node: 子节点\n",
    "        \"\"\"\n",
    "        self.tree[val] = node\n",
    "\n",
    "    def predict(self, features):\n",
    "        \"\"\"\n",
    "        对于一个样本，根据当前决策树进行预测结果\n",
    "        :param features: 输入样本\n",
    "        \"\"\"\n",
    "        if self.root is True: # 如果当前节点是根节点，直接返回该节点的类别\n",
    "            return self.label\n",
    "        return self.tree[features[self.feature]].predict(features)# 通过子树递归进行预测\n",
    "\n",
    "\n",
    "class DTree:\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self._tree = {}\n",
    "\n",
    "    # 熵\n",
    "    @staticmethod\n",
    "    def calc_ent(datasets):\n",
    "         \"\"\"\n",
    "        计算数据集的熵\n",
    "        \"\"\"\n",
    "        data_length = len(datasets)# 数据集样本总数\n",
    "        label_count = {}\n",
    "        for i in range(data_length):\n",
    "            label = datasets[i][-1] # 获取当前样本的标签\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0# 如果该标签第一次出现，将其加入统计字典中\n",
    "            label_count[label] += 1#统计该标签出现的次数\n",
    "        ent = -sum([(p / data_length) * log(p / data_length, 2) # 计算信息熵\n",
    "                    for p in label_count.values()])\n",
    "        return ent\n",
    "\n",
    "    # 经验条件熵\n",
    "    def cond_ent(self, datasets, axis=0):\n",
    "        \"\"\"\n",
    "        计算数据集 关于第axis个特征 的条件熵\n",
    "        \"\"\"\n",
    "        data_length = len(datasets) # 数据集样本总数\n",
    "        feature_sets = {}# 初始化空字典，用于将数据按照某一特征分组\n",
    "        for i in range(data_length):\n",
    "            feature = datasets[i][axis] # 获取第axis个特征值\n",
    "            if feature not in feature_sets:\n",
    "                feature_sets[feature] = []\n",
    "            feature_sets[feature].append(datasets[i])# 将具有相同特征值的数据添加到同一组\n",
    "        cond_ent = sum([(len(p) / data_length) * self.calc_ent(p)# 计算条件熵\n",
    "                        for p in feature_sets.values()])\n",
    "        return cond_ent\n",
    "\n",
    "    # 信息增益\n",
    "    @staticmethod\n",
    "    def info_gain(ent, cond_ent):\n",
    "        return ent - cond_ent# 计算信息增益\n",
    "\n",
    "    def info_gain_train(self, datasets):\n",
    "        count = len(datasets[0]) - 1 # 数据集中特征数量\n",
    "        ent = self.calc_ent(datasets)# 计算数据集的信息熵\n",
    "        best_feature = []# 存储所有特征的信息增益\n",
    "        for c in range(count):# 对数据集中的每个特征，计算其信息增益并存储\n",
    "            c_info_gain = self.info_gain(ent, self.cond_ent(datasets, axis=c))\n",
    "            best_feature.append((c, c_info_gain))\n",
    "        # 比较大小\n",
    "        best_ = max(best_feature, key=lambda x: x[-1]) # 选择信息增益最大的特征\n",
    "        return best_\n",
    "\n",
    "    def train(self, train_data):\n",
    "        \"\"\"\n",
    "        input:数据集D(DataFrame格式)，特征集A，阈值eta\n",
    "        output:决策树T\n",
    "        \"\"\"\n",
    "        _, y_train, features = train_data.iloc[:, :\n",
    "                                               -1], train_data.iloc[:,\n",
    "                                                                    -1], train_data.columns[:\n",
    "                                                                                            -1]## 分离D中的特征和标签\n",
    "        # 1,若D中实例属于同一类Ck，则T为单节点树，并将类Ck作为结点的类标记，返回T\n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return Node(root=True, label=y_train.iloc[0])\n",
    "\n",
    "        # 2, 若A为空，则T为单节点树，将D中实例树最大的类Ck作为该节点的类标记，返回T\n",
    "        if len(features) == 0:\n",
    "            return Node(\n",
    "                root=True,\n",
    "                label=y_train.value_counts().sort_values(\n",
    "                    ascending=False).index[0])\n",
    "\n",
    "        # 3,计算最大信息增益 同5.1,Ag为信息增益最大的特征\n",
    "        max_feature, max_info_gain = self.info_gain_train(np.array(train_data))\n",
    "        max_feature_name = features[max_feature]\n",
    "\n",
    "        # 4,Ag的信息增益小于阈值eta,则置T为单节点树，并将D中是实例数最大的类Ck作为该节点的类标记，返回T\n",
    "        if max_info_gain < self.epsilon:\n",
    "            return Node(\n",
    "                root=True,\n",
    "                label=y_train.value_counts().sort_values(\n",
    "                    ascending=False).index[0])\n",
    "\n",
    "        # 5,构建Ag子集\n",
    "        node_tree = Node(\n",
    "            root=False, feature_name=max_feature_name, feature=max_feature)\n",
    "\n",
    "        feature_list = train_data[max_feature_name].value_counts().index\n",
    "        for f in feature_list:# 获取数据集Dv\n",
    "            sub_train_df = train_data.loc[train_data[max_feature_name] ==\n",
    "                                          f].drop([max_feature_name], axis=1)\n",
    "\n",
    "            # 6, 递归生成树\n",
    "            sub_tree = self.train(sub_train_df)\n",
    "            node_tree.add_node(f, sub_tree)\n",
    "\n",
    "        # pprint.pprint(node_tree.tree)\n",
    "        return node_tree# 返回构建好的树\n",
    "\n",
    "    def fit(self, train_data):\n",
    "    \"\"\"\n",
    "    这个方法用来训练模型，给定训练数据train_data作为输入，并使用这些数据来训练机器学习模型。\n",
    "    \"\"\"\n",
    "        self._tree = self.train(train_data)\n",
    "    \"\"\"\n",
    "    训练数据train_data被传递给了train方法，该方法返回了一个训练好的模型_tree。\n",
    "    这个模型被保存在了类属性self._tree中。\n",
    "   \"\"\"\n",
    "        return self._tree\n",
    "\n",
    "    def predict(self, X_test):\n",
    "  \"\"\"\n",
    "    这个方法用于对测试数据进行预测，给定测试数据X_test作为输入。\n",
    "\"\"\"\n",
    "        return self._tree.predict(X_test)\n",
    "\"\"\"\n",
    "    预测使用的是训练好的模型self._tree，对测试数据X_test进行预测并返回结果。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, labels = create_data()\n",
    "'''\n",
    "这一行代码调用了一个自定义函数create_data()，该函数返回一个包含训练数据和标签的元组（datasets, labels）。\n",
    "这一行代码将返回结果解包，并将训练数据赋值给datasets，将标签赋值给labels。\n",
    "'''\n",
    "data_df = pd.DataFrame(datasets, columns=labels)\n",
    "'''\n",
    "这一行代码使用Pandas库将训练数据转换为数据框DataFrame类型，并将标签labels作为列名。\n",
    "'''\n",
    "dt = DTree()\n",
    "'''\n",
    "这一行代码实例化了一个名为DTree的类，这个类很可能是实现了一个决策树算法。\n",
    "'''\n",
    "tree = dt.fit(data_df)\n",
    "'''\n",
    "这一行代码使用上面实例化的决策树模型dt的fit()方法对data_df进行拟合（即训练）操作。\n",
    "训练好的决策树被赋值给tree变量，该变量可以被用于之后的测试数据预测等操作。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label:': None, 'feature': 2, 'tree': {'否': {'label:': None, 'feature': 1, 'tree': {'否': {'label:': '否', 'feature': None, 'tree': {}}, '是': {'label:': '是', 'feature': None, 'tree': {}}}}, '是': {'label:': '是', 'feature': None, 'tree': {}}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree#训练好的决策树模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'否'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.predict(['老年', '否', '否', '一般'])\n",
    "'''\n",
    "这一行代码使用了DTree类的predict()方法，参数是一个包含待预测的样本的列表。\n",
    "给定一个新的数据样本，该方法会对其进行预测并返回预测结果。\n",
    "具体预测的流程可能是使用之前训练好的决策树模型（即之前fit()方法返回的树），按照决策树的规则进行预测分类。\n",
    "在这里，传入的参数是一个包含4个属性的列表，具体每个属性的含义需要结合具体的样本数据来理解。\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def create_data():#定义一个函数，函数名为create_data\n",
    "    iris = load_iris()#加载Iris数据集,将鸢尾花数据集载入到iris变量中\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)#使用iris中的数据构建一个DataFrame对象df，并将其列名设置为特征名\n",
    "    df['label'] = iris.target#将鸢尾花数据集的标签加入到df中\n",
    "    df.columns = [\n",
    "        'sepal length', 'sepal width', 'petal length', 'petal width', 'label'\n",
    "    ]#对DataFrame的列名进行了修改\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])#将所有行和前两列(sepal length和sepal width)以及最后一列(label)构成新的数据集data。\n",
    "    # print(data)\n",
    "    return data[:, :2], data[:, -1]#返回新数据集的前两列(sepal length和sepal width)以及标签列(label)\n",
    "\n",
    "\n",
    "X, y = create_data()#调用create_data()函数，将返回的特征数据和标签分别保存在X和y中\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)#使用train_test_split函数将数据集分为训练集和测试集，并将训练集特征数据、测试集特征数据、训练集标签以及测试集标签分别保存在X_train、X_test、y_train和y_test中。其中，test_size参数设置为0.3，表示测试集的比例为30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # 导入决策树分类器算法\n",
    "from sklearn.tree import export_graphviz # 导入输出决策树图形的函数\n",
    "import graphviz # 导入graphviz库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier() # 创建一个决策树分类器对象\n",
    "clf.fit(X_train, y_train,)# 使用 X_train 和 y_train 训练分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)#使用测试集数据评估分类器的准确度得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pic = export_graphviz(clf, out_file=\"mytree.pdf\")#生成一个名为mytree.pdf的决策树可视化图\n",
    "with open('mytree.pdf') as f:\n",
    "    dot_graph = f.read()#将该决策树可视化图的内容读取并保存在变量dot_graph中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"495pt\" height=\"373pt\"\r\n",
       " viewBox=\"0.00 0.00 495.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-369 491,-369 491,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"322.5,-365 218.5,-365 218.5,-297 322.5,-297 322.5,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"270.5\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[0] &lt;= 5.55</text>\r\n",
       "<text text-anchor=\"middle\" x=\"270.5\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"270.5\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 70</text>\r\n",
       "<text text-anchor=\"middle\" x=\"270.5\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [34, 36]</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"261.5,-261 163.5,-261 163.5,-193 261.5,-193 261.5,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[1] &lt;= 2.8</text>\r\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.229</text>\r\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 38</text>\r\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [33, 5]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.669,-296.884C246.807,-288.332 241.508,-279.013 236.423,-270.072\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"239.421,-268.262 231.435,-261.299 233.335,-271.722 239.421,-268.262\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"224.806\" y=\"-281.704\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"377.5,-261 279.5,-261 279.5,-193 377.5,-193 377.5,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[1] &lt;= 3.7</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.061</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 32</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 31]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>0&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M289.331,-296.884C294.193,-288.332 299.492,-279.013 304.577,-270.072\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"307.665,-271.722 309.565,-261.299 301.579,-268.262 307.665,-271.722\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"316.194\" y=\"-281.704\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"145,-157 54,-157 54,-89 145,-89 145,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"99.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[0] &lt;= 4.7</text>\r\n",
       "<text text-anchor=\"middle\" x=\"99.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.278</text>\r\n",
       "<text text-anchor=\"middle\" x=\"99.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 6</text>\r\n",
       "<text text-anchor=\"middle\" x=\"99.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 5]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M175.812,-192.884C165.648,-183.709 154.505,-173.65 143.95,-164.123\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"146.159,-161.402 136.39,-157.299 141.468,-166.598 146.159,-161.402\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"261.5,-149.5 163.5,-149.5 163.5,-96.5 261.5,-96.5 261.5,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 32</text>\r\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-104.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [32, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>1&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M212.5,-192.884C212.5,-182.326 212.5,-170.597 212.5,-159.854\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216,-159.52 212.5,-149.52 209,-159.52 216,-159.52\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91,-53 0,-53 0,-0 91,-0 91,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"45.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"45.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"45.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M80.6134,-88.9485C75.6474,-80.2579 70.2776,-70.8608 65.2667,-62.0917\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"68.207,-60.1826 60.2067,-53.2367 62.1293,-63.6557 68.207,-60.1826\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"200,-53 109,-53 109,-0 200,-0 200,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 5]</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>2&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.736,-88.9485C123.794,-80.2579 129.264,-70.8608 134.367,-62.0917\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"137.516,-63.6401 139.521,-53.2367 131.466,-60.1189 137.516,-63.6401\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"377.5,-149.5 279.5,-149.5 279.5,-96.5 377.5,-96.5 377.5,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 31</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-104.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 31]</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>6&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M328.5,-192.884C328.5,-182.326 328.5,-170.597 328.5,-159.854\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"332,-159.52 328.5,-149.52 325,-159.52 332,-159.52\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"487,-149.5 396,-149.5 396,-96.5 487,-96.5 487,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"441.5\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"441.5\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"441.5\" y=\"-104.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>6&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M365.188,-192.884C378.103,-181.226 392.599,-168.141 405.46,-156.532\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"408.15,-158.819 413.228,-149.52 403.46,-153.622 408.15,-158.819\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1f159bc2780>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphviz.Source(dot_graph)# 用 graphviz 模块将 dot graph 转换成可视化的图形对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "参考代码：https://github.com/wzyonggege/statistical-learning-method\n",
    "\n",
    "本文代码更新地址：https://github.com/fengdu78/lihang-code\n",
    "\n",
    "中文注释制作：机器学习初学者公众号：ID:ai-start-com\n",
    "\n",
    "配置环境：python 3.5+\n",
    "\n",
    "代码全部测试通过。\n",
    "![gongzhong](../gongzhong.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
