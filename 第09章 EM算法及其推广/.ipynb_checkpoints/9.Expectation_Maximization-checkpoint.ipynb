{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9章 EM算法及其推广"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization algorithm\n",
    "\n",
    "### Maximum likehood function\n",
    "\n",
    "[likehood & maximum likehood](http://fangs.in/post/thinkstats/likelihood/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．EM算法是含有隐变量的概率模型极大似然估计或极大后验概率估计的迭代算法。含有隐变量的概率模型的数据表示为$\\theta$ )。这里，$Y$是观测变量的数据，$Z$是隐变量的数据，$\\theta$ 是模型参数。EM算法通过迭代求解观测数据的对数似然函数${L}(\\theta)=\\log {P}(\\mathrm{Y} | \\theta)$的极大化，实现极大似然估计。每次迭代包括两步：\n",
    "\n",
    "$E$步，求期望，即求$logP\\left(Z | Y, \\theta\\right)$ )关于$ P\\left(Z | Y, \\theta^{(i)}\\right)$)的期望：\n",
    "\n",
    "$$Q\\left(\\theta, \\theta^{(i)}\\right)=\\sum_{Z} \\log P(Y, Z | \\theta) P\\left(Z | Y, \\theta^{(i)}\\right)$$\n",
    "称为$Q$函数，这里$\\theta^{(i)}$是参数的现估计值；\n",
    "\n",
    "$M$步，求极大，即极大化$Q$函数得到参数的新估计值：\n",
    "\n",
    "$$\\theta^{(i+1)}=\\arg \\max _{\\theta} Q\\left(\\theta, \\theta^{(i)}\\right)$$\n",
    " \n",
    "在构建具体的EM算法时，重要的是定义$Q$函数。每次迭代中，EM算法通过极大化$Q$函数来增大对数似然函数${L}(\\theta)$。\n",
    "\n",
    "2．EM算法在每次迭代后均提高观测数据的似然函数值，即\n",
    "\n",
    "$$P\\left(Y | \\theta^{(i+1)}\\right) \\geqslant P\\left(Y | \\theta^{(i)}\\right)$$\n",
    "\n",
    "在一般条件下EM算法是收敛的，但不能保证收敛到全局最优。\n",
    "\n",
    "3．EM算法应用极其广泛，主要应用于含有隐变量的概率模型的学习。高斯混合模型的参数估计是EM算法的一个重要应用，下一章将要介绍的隐马尔可夫模型的非监督学习也是EM算法的一个重要应用。\n",
    "\n",
    "4．EM算法还可以解释为$F$函数的极大-极大算法。EM算法有许多变形，如GEM算法。GEM算法的特点是每次迭代增加$F$函数值（并不一定是极大化$F$函数），从而增加似然函数值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在统计学中，似然函数（likelihood function，通常简写为likelihood，似然）是一个非常重要的内容，在非正式场合似然和概率（Probability）几乎是一对同义词，但是在统计学中似然和概率却是两个不同的概念。概率是在特定环境下某件事情发生的可能性，也就是结果没有产生之前依据环境所对应的参数来预测某件事情发生的可能性，比如抛硬币，抛之前我们不知道最后是哪一面朝上，但是根据硬币的性质我们可以推测任何一面朝上的可能性均为50%，这个概率只有在抛硬币之前才是有意义的，抛完硬币后的结果便是确定的；而似然刚好相反，是在确定的结果下去推测产生这个结果的可能环境（参数），还是抛硬币的例子，假设我们随机抛掷一枚硬币1,000次，结果500次人头朝上，500次数字朝上（实际情况一般不会这么理想，这里只是举个例子），我们很容易判断这是一枚标准的硬币，两面朝上的概率均为50%，这个过程就是我们运用出现的结果来判断这个事情本身的性质（参数），也就是似然。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(Y|\\theta) = \\prod[\\pi p^{y_i}(1-p)^{1-y_i}+(1-\\pi) q^{y_i}(1-q)^{1-y_i}]$$\n",
    "\n",
    "### E step:\n",
    "\n",
    "$$\\mu^{i+1}=\\frac{\\pi (p^i)^{y_i}(1-(p^i))^{1-y_i}}{\\pi (p^i)^{y_i}(1-(p^i))^{1-y_i}+(1-\\pi) (q^i)^{y_i}(1-(q^i))^{1-y_i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np#导入NumPy库，用作进行各种数学运算和数组处理\n",
    "import math#导入math库，用于各种数学计算和函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_A, pro_B, por_C = 0.5, 0.5, 0.5\n",
    "\n",
    "\n",
    "def pmf(i, pro_A, pro_B, por_C):# 定义概率质量函数pmf\n",
    "    pro_1 = pro_A * math.pow(pro_B, data[i]) * math.pow(\n",
    "        (1 - pro_B), 1 - data[i])# 将先验概率pro_A和两种不同情况下的似然函数计算结果相乘，赋值给pro_1\n",
    "    pro_2 = pro_A * math.pow(pro_C, data[i]) * math.pow(\n",
    "        (1 - pro_C), 1 - data[i])\n",
    "    # 将先验概率pro_A和两种不同情况下的似然函数计算结果相乘，赋值给pro_2\n",
    "# 其中，数据集中第i个元素的出现情况用变量data[i]表示\n",
    "    return pro_1 / (pro_1 + pro_2)# 返回计算结果pro_1和pro_2的比值，即后验概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M step:\n",
    "\n",
    "$$\\pi^{i+1}=\\frac{1}{n}\\sum_{j=1}^n\\mu^{i+1}_j$$\n",
    "#根据 EM 算法，计算下一轮的 A/B/C 三个分类的先验概率，即各自的频率占比\n",
    "\n",
    "$$p^{i+1}=\\frac{\\sum_{j=1}^n\\mu^{i+1}_jy_i}{\\sum_{j=1}^n\\mu^{i+1}_j}$$\n",
    "#计算下一轮迭代的 B 类样本的生成概率\n",
    "\n",
    "$$q^{i+1}=\\frac{\\sum_{j=1}^n(1-\\mu^{i+1}_jy_i)}{\\sum_{j=1}^n(1-\\mu^{i+1}_j)}$$\n",
    "#计算下一轮迭代的 C 类样本（非 B 类的样本）的生成概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EM:# 定义一个名为EM的类\n",
    "    def __init__(self, prob):#定义该类的初始化函数，接受一个长度为3的prob列表作为参数\n",
    "        self.pro_A, self.pro_B, self.pro_C = prob# 将传入的prob列表中的值分别赋给类内的self.pro_A、self.pro_B、self.pro_C\n",
    "\n",
    "    # e_step\n",
    "    def pmf(self, i): # 定义函数pmf，该函数接受一个索引值i作为参数，返回第i个样本点的后验概率\n",
    "        pro_1 = self.pro_A * math.pow(self.pro_B, data[i]) * math.pow(\n",
    "            (1 - self.pro_B), 1 - data[i])\n",
    "         # 将先验概率pro_A和似然函数计算结果相乘，赋值给pro_1\n",
    "    # 其中，数据集中第i个元素的出现情况用变量data[i]表示\n",
    "    # math.pow(a,b)函数表示a的b次方\n",
    "        pro_2 = (1 - self.pro_A) * math.pow(self.pro_C, data[i]) * math.pow(\n",
    "            (1 - self.pro_C), 1 - data[i])\n",
    "        # 将（1-pro_A）和似然函数计算结果相乘，赋值给pro_2\n",
    "    # 其中，数据集中第i个元素的出现情况用变量data[i]表示\n",
    "        return pro_1 / (pro_1 + pro_2)\n",
    "     # 返回计算结果pro_1和pro_2的比值，即后验概率\n",
    "    # m_step\n",
    "    def fit(self, data):\n",
    "        # 定义一个名为fit的方法，该方法接受一个数据集data作为参数\n",
    "        count = len(data)\n",
    "         # 获取数据集的长度\n",
    "        print('init prob:{}, {}, {}'.format(self.pro_A, self.pro_B,\n",
    "         # 打印初始的概率值                                   self.pro_C))\n",
    "        for d in range(count):\n",
    "            _ = yield\n",
    "                                            \n",
    "        # 让该函数变成一个生成器\n",
    "        # 对于外部调用者而言，只需要不断地调用next()方法就可以迭代执行该函数内的代码\n",
    "            _pmf = [self.pmf(k) for k in range(count)]# 调用pmf()方法计算当前后验概率\n",
    "            pro_A = 1 / count * sum(_pmf) # 计算先验概率pro_A\n",
    "            pro_B = sum([_pmf[k] * data[k] for k in range(count)]) / sum(\n",
    "                [_pmf[k] for k in range(count)]) # 计算似然概率pro_B\n",
    "            pro_C = sum([(1 - _pmf[k]) * data[k]# 计算似然概率pro_C\n",
    "                         for k in range(count)]) / sum([(1 - _pmf[k])\n",
    "                                                        for k in range(count)])\n",
    "            print('{}/{}  pro_a:{:.3f}, pro_b:{:.3f}, pro_c:{:.3f}'.format(\n",
    "                d + 1, count, pro_A, pro_B, pro_C))# 打印当前迭代次数、先验概率、似然概率 pro_B 和 pro_C 的数值\n",
    "            self.pro_A = pro_A\n",
    "            self.pro_B = pro_B\n",
    "            self.pro_C = pro_C\n",
    "            # 更新类内的先验概率pro_A、似然概率pro_B和pro_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[1,1,0,1,0,0,1,0,1,1]#定义一个长度为10的列表data，表示样本的观测值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init prob:0.5, 0.5, 0.5\n"
     ]
    }
   ],
   "source": [
    "em = EM(prob=[0.5, 0.5, 0.5])#创建一个EM类的实例em，传入先验概率值为0.5的三个概率参数\n",
    "f = em.fit(data)#调用em的fit方法，并用变量f保存它的返回值\n",
    "next(f)#执行f，让函数继续运行到下一个yield语句处"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10  pro_a:0.500, pro_b:0.600, pro_c:0.600\n"
     ]
    }
   ],
   "source": [
    "# 第一次迭代\n",
    "f.send(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10  pro_a:0.500, pro_b:0.600, pro_c:0.600\n"
     ]
    }
   ],
   "source": [
    "# 第二次\n",
    "f.send(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init prob:0.4, 0.6, 0.7\n"
     ]
    }
   ],
   "source": [
    "em = EM(prob=[0.4, 0.6, 0.7])#创建一个EM类的实例，传入先验概率值为[0.4, 0.6, 0.7]三个概率参数\n",
    "f2 = em.fit(data)#调用em的fit方法，并用变量f2保存它的返回值\n",
    "next(f2)#执行f2，让函数继续运行到下一个yield语句处"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10  pro_a:0.406, pro_b:0.537, pro_c:0.643\n"
     ]
    }
   ],
   "source": [
    "f2.send(1)#执行该语句，让EM中的fit方法继续运行一步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10  pro_a:0.406, pro_b:0.537, pro_c:0.643\n"
     ]
    }
   ],
   "source": [
    "f2.send(2)#执行该语句，同样让em的fit方法继续运行一步，进行当前的一次迭代计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "参考代码：https://github.com/wzyonggege/statistical-learning-method\n",
    "\n",
    "本文代码更新地址：https://github.com/fengdu78/lihang-code\n",
    "\n",
    "中文注释制作：机器学习初学者公众号：ID:ai-start-com\n",
    "\n",
    "配置环境：python 3.5+\n",
    "\n",
    "代码全部测试通过。\n",
    "![gongzhong](../gongzhong.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
